import random

import streamlit as st
import torch
from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler

repo = "runwayml/stable-diffusion-v1-5"
euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(repo, subfolder="scheduler")

@st.cache(hash_funcs={torch.nn.parameter.Parameter: lambda _: None}, allow_output_mutation=True)
def load_model():
    return StableDiffusionPipeline.from_pretrained(
        repo, scheduler=euler_ancestral_scheduler, torch_dtype=torch.float32, revision="fp16"
    ).to("cpu")
#pipe.enable_sequential_cpu_offload()
#pipe.enable_attention_slicing(1)

diffuser = load_model()

# ì›¹ í˜ì´ì§€ ì œëª©
st.title("ê·¸ë¦¼ì„ ê·¸ë ¤ë“œë ¤ìš”! ğŸ¤“")
# ì›¹ í˜ì´ì§€ ë¶€ì œëª©
st.subheader('ëª‡ ê°€ì§€ ì œì‹œì–´ë¥¼ ë¶€íƒë“œë¦´ê²Œìš”!')

# ì›¹ í˜ì´ì§€ì— ì…ë ¥
with st.form(key="form"):
    prompt = st.text_input(label="ì œì‹œì–´", placeholder="í™”ì„±ì—ì„œ ë§ì„ íƒ€ê³  ìˆëŠ” ìš°ì£¼ì¸ ì‚¬ì§„")
    submit = st.form_submit_button("Go!")

# ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ, ì‘ë™ë˜ëŠ” ì½”ë“œ
if submit:
    st.write("ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”!... ğŸ¤“")

    # ëª¨ë¸ì˜ inferenceê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
    with st.spinner("ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”... ğŸ¤“"):
        # classifier ë¼ëŠ” ì´ë¦„ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì‚¬ìš©.
        # ì›í•˜ëŠ” ëª¨ë¸ë¡œ ë³€ê²½í•  ìˆ˜ ìˆë‹¤.
        seed = random.randrange(10000, 99999)
        generator = torch.Generator().manual_seed(seed)
        print(prompt)
        results = diffuser(prompt,num_inference_steps=25, generator=generator).images[0]

    st.image(results, caption=prompt)